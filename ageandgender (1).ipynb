{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.5.4.60)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\lenovo\\appdata\\roaming\\python\\python38\\site-packages (from opencv-python) (1.21.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender : Male, conf = 0.948\n",
      "Age : (25-32), conf = 0.990\n",
      "Gender : Male, conf = 0.966\n",
      "Age : (25-32), conf = 0.962\n",
      "Gender : Male, conf = 0.971\n",
      "Age : (25-32), conf = 0.941\n",
      "Gender : Male, conf = 0.919\n",
      "Age : (25-32), conf = 0.974\n",
      "Gender : Male, conf = 0.827\n",
      "Age : (25-32), conf = 0.966\n",
      "Gender : Male, conf = 0.880\n",
      "Age : (25-32), conf = 0.965\n",
      "Gender : Male, conf = 0.949\n",
      "Age : (25-32), conf = 0.946\n",
      "Gender : Male, conf = 0.936\n",
      "Age : (25-32), conf = 0.753\n",
      "Gender : Male, conf = 0.939\n",
      "Age : (25-32), conf = 0.927\n",
      "Gender : Male, conf = 0.898\n",
      "Age : (25-32), conf = 0.946\n",
      "Gender : Male, conf = 0.962\n",
      "Age : (25-32), conf = 0.937\n",
      "Gender : Male, conf = 0.914\n",
      "Age : (25-32), conf = 0.966\n",
      "Gender : Male, conf = 0.978\n",
      "Age : (25-32), conf = 0.972\n",
      "Gender : Male, conf = 0.944\n",
      "Age : (25-32), conf = 0.974\n",
      "Gender : Male, conf = 0.969\n",
      "Age : (25-32), conf = 0.979\n",
      "Gender : Male, conf = 0.961\n",
      "Age : (25-32), conf = 0.987\n",
      "Gender : Male, conf = 0.943\n",
      "Age : (25-32), conf = 0.987\n",
      "Gender : Male, conf = 0.973\n",
      "Age : (25-32), conf = 0.989\n",
      "Gender : Male, conf = 0.921\n",
      "Age : (25-32), conf = 0.992\n",
      "Gender : Male, conf = 0.915\n",
      "Age : (25-32), conf = 0.954\n",
      "Gender : Male, conf = 0.906\n",
      "Age : (25-32), conf = 0.925\n",
      "Gender : Male, conf = 0.983\n",
      "Age : (25-32), conf = 0.882\n",
      "Gender : Male, conf = 0.992\n",
      "Age : (25-32), conf = 0.984\n",
      "Gender : Male, conf = 0.991\n",
      "Age : (25-32), conf = 0.968\n",
      "Gender : Male, conf = 0.848\n",
      "Age : (25-32), conf = 0.975\n",
      "Gender : Male, conf = 0.880\n",
      "Age : (25-32), conf = 0.979\n",
      "Gender : Male, conf = 0.923\n",
      "Age : (25-32), conf = 0.977\n",
      "Gender : Male, conf = 0.985\n",
      "Age : (25-32), conf = 0.833\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ce6adbec4371>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m     \u001b[0mframeFace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbboxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetFaceBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaceNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No face Detected, Checking next frame\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-ce6adbec4371>\u001b[0m in \u001b[0;36mgetFaceBox\u001b[1;34m(net, frame, conf_threshold)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m#after preprocessing the image it is passed to neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdetections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;31m#net.forward will gives the output after processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "#conf_threshold means if the accuracy of recognizing the correct result is greater than 70% then only it will the result be displayed\n",
    "\n",
    "def getFaceBox(net, frame, conf_threshold=0.7): \n",
    "    frameOpencvDnn = frame.copy() #inputting the frame\n",
    "    frameHeight = frameOpencvDnn.shape[0] \n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    #creating a 4 dimesional array of image\n",
    "    blob = cv.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "    #by default scale factor is 1.0,resizing the frame to 300X300,mean subtractoin value,swaprb is true to convert BGR to RGB,crop is false, we want the actaul size of the image\n",
    "    \n",
    "    net.setInput(blob)\n",
    "    #after preprocessing the image it is passed to neural network\n",
    "    \n",
    "    detections = net.forward()\n",
    "    #net.forward will gives the output after processing\n",
    "    \n",
    "    bboxes = []\n",
    "    #loop for drawing rectangle on the identified face\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes\n",
    "parser = argparse.ArgumentParser(description='Use this script to run age and gender recognition using OpenCV.')\n",
    "parser.add_argument('--input', help='Path to input image or video file. Skip this argument to capture frames from a camera.')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "faceProto = \"opencv_face_detector.pbtxt\"\n",
    "faceModel = \"opencv_face_detector_uint8.pb\"\n",
    "\n",
    "ageProto = \"age_deploy.prototxt\"\n",
    "ageModel = \"age_net.caffemodel\"\n",
    "\n",
    "genderProto = \"gender_deploy.prototxt\"\n",
    "genderModel = \"gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "ageList = ['(0-2)', '(4-6)', '(8-12)', '(15-20)', '(25-32)', '(38-43)', '(48-53)', '(60-80)']\n",
    "genderList = ['Male', 'Female']\n",
    "\n",
    "# Load network\n",
    "ageNet = cv.dnn.readNet(ageModel, ageProto)\n",
    "genderNet = cv.dnn.readNet(genderModel, genderProto)\n",
    "faceNet = cv.dnn.readNet(faceModel, faceProto)\n",
    "\n",
    "# Open a video file or an image file or a camera stream\n",
    "cap = cv.VideoCapture(args.input if args.input else 0)\n",
    "padding = 20\n",
    "\n",
    "while cv.waitKey(1) < 0: #while the video is still on/or you haven't exit\n",
    "    # Read frame\n",
    "    t = time.time()\n",
    "    hasFrame, frame = cap.read()\n",
    "    if not hasFrame: #if there is not frame break the video\n",
    "        cv.waitKey()\n",
    "        break\n",
    "\n",
    "    frameFace, bboxes = getFaceBox(faceNet, frame)\n",
    "    if not bboxes:\n",
    "       print(\"No face Detected, Checking next frame\")\n",
    "#      continue\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        # print(bbox)\n",
    "        face = frame[max(0,bbox[1]-padding):min(bbox[3]+padding,frame.shape[0]-1),max(0,bbox[0]-padding):min(bbox[2]+padding, frame.shape[1]-1)]\n",
    "\n",
    "        #      for gender preediction\n",
    "        blob = cv.dnn.blobFromImage(face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "        genderNet.setInput(blob)\n",
    "        genderPreds = genderNet.forward()\n",
    "        gender = genderList[genderPreds[0].argmax()]\n",
    "        # print(\"Gender Output : {}\".format(genderPreds))\n",
    "        print(\"Gender : {}, conf = {:.3f}\".format(gender, genderPreds[0].max()))\n",
    "\n",
    "        #      for age preediction\n",
    "        ageNet.setInput(blob)\n",
    "        agePreds = ageNet.forward()\n",
    "        age = ageList[agePreds[0].argmax()]\n",
    "        print(\"Age : {}, conf = {:.3f}\".format(age, agePreds[0].max()))\n",
    "\n",
    "        label = \"{},{}\".format(gender, age)\n",
    "        cv.putText(frameFace, label, (bbox[0], bbox[1]-10), cv.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2, cv.LINE_AA)\n",
    "        cv.imshow(\"Age Gender\", frameFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
